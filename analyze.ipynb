{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_wrong_indices(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        log_content = file.read()\n",
    "    matches = re.findall(r'index: (\\d+)[\\s|\\n|\\|]+\\|\\sWrong!', log_content, re.DOTALL)\n",
    "    wrong_indices = [int(match) for match in matches]\n",
    "    return wrong_indices\n",
    "\n",
    "file_path = '/home/yl3427/cylab/selfCorrectionAgent/result_mixtral.log'\n",
    "# '/home/yl3427/cylab/selfCorrectionAgent/result_mixtral.log'\n",
    "# '/home/yl3427/cylab/selfCorrectionAgent/result_llama3.log'\n",
    "\n",
    "wrong_indices = find_wrong_indices(file_path)\n",
    "\n",
    "print(\"Indices with 'Wrong!':\", wrong_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(wrong_indices)-1):\n",
    "    if wrong_indices[i] > wrong_indices[i+1]:\n",
    "        print(i)\n",
    "        print(wrong_indices[i: i+2])\n",
    "        indices.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = indices[0]+1\n",
    "idx2 = indices[1]+1\n",
    "base = set(wrong_indices[:idx1])\n",
    "always = set(wrong_indices[idx1:idx2])\n",
    "condition = set(wrong_indices[idx2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(base & always), base & always # 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(base - always), base - always "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(always - base),always - base # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "brca_report = pd.read_csv(\"/secure/shared_data/rag_tnm_results/summary/5_folds_summary/brca_df.csv\")\n",
    "sample_reports = brca_report.iloc[:500, :]\n",
    "\n",
    "sample_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(always - base):\n",
    "    print(f\"T{sample_reports.iloc[i].t+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarity(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        log_content = file.read()\n",
    "    matches = re.findall(r'similarity: (\\d+)', log_content, re.DOTALL)\n",
    "    scores = [int(match) for match in matches]\n",
    "    return scores\n",
    "\n",
    "file_path = '/home/yl3427/cylab/selfCorrectionAgent/result_llama3.log'\n",
    "\n",
    "# '/home/yl3427/cylab/selfCorrectionAgent/result_mixtral.log'\n",
    "# '/home/yl3427/cylab/selfCorrectionAgent/result_llama3.log'\n",
    "\n",
    "similarity_scores = find_similarity(file_path)\n",
    "\n",
    "print(similarity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "index = range(0, 500)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(index, similarity_scores)\n",
    "plt.xlabel('index of report')\n",
    "plt.ylabel('similiarity between created rules and the existing rules (memory)')\n",
    "plt.xlim(0, 500)\n",
    "plt.xticks(np.arange(0, 501, 25))  # Adjust the interval as needed\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "index = range(0, 80)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(index, similarity_scores[:80])\n",
    "plt.xlabel('index of report')\n",
    "plt.ylabel('similiarity between created rules and the existing rules (memory)')\n",
    "plt.xlim(0, 80)\n",
    "plt.xticks(np.arange(0, 80, 5))  # Adjust the interval as needed\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_memory(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        log_content = file.read()\n",
    "    matches = re.findall(r\" memory: (\\[.*?\\])\", log_content, re.DOTALL)\n",
    "    wrong_indices = [ast.literal_eval(match) for match in matches]\n",
    "    return wrong_indices\n",
    "\n",
    "file_path = '/home/yl3427/cylab/selfCorrectionAgent/memory.txt'\n",
    "\n",
    "\n",
    "wrong_indices = find_memory(file_path)\n",
    "\n",
    "print(len(wrong_indices))\n",
    "print(wrong_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from src.metrics import relax_n03_performance_report, n03_performance_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zshot\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.95      0.94      0.95       316\n",
      "          N1       0.86      0.87      0.87       300\n",
      "          N2       0.63      0.71      0.67       110\n",
      "          N3       0.90      0.76      0.82        74\n",
      "\n",
      "    accuracy                           0.86       800\n",
      "   macro avg       0.84      0.82      0.83       800\n",
      "weighted avg       0.87      0.86      0.87       800\n",
      "\n",
      "\n",
      "conditional memory, test size: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.95      0.95       315\n",
      "          N1       0.86      0.90      0.88       295\n",
      "          N2       0.68      0.74      0.71       108\n",
      "          N3       1.00      0.67      0.80        72\n",
      "\n",
      "    accuracy                           0.88       790\n",
      "   macro avg       0.87      0.81      0.83       790\n",
      "weighted avg       0.88      0.88      0.88       790\n",
      "\n",
      "\n",
      "conditional memory, test size: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl3427/miniconda3/envs/selfCorrection/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2628: UserWarning: labels size, 4, does not match size of target_names, 5\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.97      0.95       306\n",
      "          N1       0.89      0.84      0.87       290\n",
      "          N2       0.67      0.81      0.73       108\n",
      "          N3       0.96      0.75      0.84        71\n",
      "\n",
      "    accuracy                           0.88       775\n",
      "   macro avg       0.87      0.84      0.85       775\n",
      "weighted avg       0.89      0.88      0.88       775\n",
      "\n",
      "\n",
      "conditional memory, test size: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.95      0.97      0.96       309\n",
      "          N1       0.90      0.84      0.87       292\n",
      "          N2       0.65      0.77      0.70       105\n",
      "          N3       0.90      0.77      0.83        71\n",
      "\n",
      "    accuracy                           0.88       777\n",
      "   macro avg       0.85      0.84      0.84       777\n",
      "weighted avg       0.89      0.88      0.88       777\n",
      "\n",
      "\n",
      "conditional memory, test size: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.98      0.96       308\n",
      "          N1       0.89      0.88      0.89       286\n",
      "          N2       0.72      0.70      0.71       107\n",
      "          N3       0.88      0.79      0.83        72\n",
      "\n",
      "    accuracy                           0.89       773\n",
      "   macro avg       0.86      0.84      0.85       773\n",
      "weighted avg       0.89      0.89      0.89       773\n",
      "\n",
      "\n",
      "conditional memory, test size: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.90      0.92       240\n",
      "          N1       0.82      0.94      0.88       265\n",
      "          N2       0.79      0.67      0.72       100\n",
      "          N3       0.91      0.74      0.82        66\n",
      "\n",
      "    accuracy                           0.86       671\n",
      "   macro avg       0.86      0.81      0.83       671\n",
      "weighted avg       0.87      0.86      0.86       671\n",
      "\n",
      "\n",
      "conditional memory, test size: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.93      0.93       300\n",
      "          N1       0.84      0.89      0.87       285\n",
      "          N2       0.70      0.69      0.69       107\n",
      "          N3       1.00      0.77      0.87        70\n",
      "\n",
      "    accuracy                           0.87       762\n",
      "   macro avg       0.87      0.82      0.84       762\n",
      "weighted avg       0.87      0.87      0.87       762\n",
      "\n",
      "\n",
      "conditional memory, test size: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.98      0.96       299\n",
      "          N1       0.90      0.85      0.87       281\n",
      "          N2       0.68      0.78      0.73       102\n",
      "          N3       0.90      0.80      0.85        69\n",
      "\n",
      "    accuracy                           0.89       751\n",
      "   macro avg       0.86      0.85      0.85       751\n",
      "weighted avg       0.89      0.89      0.89       751\n",
      "\n",
      "\n",
      "conditional memory, test size: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.93      0.98      0.95       299\n",
      "          N1       0.89      0.88      0.88       284\n",
      "          N2       0.71      0.70      0.71       100\n",
      "          N3       0.90      0.80      0.85        70\n",
      "\n",
      "    accuracy                           0.89       753\n",
      "   macro avg       0.86      0.84      0.85       753\n",
      "weighted avg       0.88      0.89      0.88       753\n",
      "\n",
      "\n",
      "conditional memory, test size: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.96      0.93      0.95       291\n",
      "          N1       0.86      0.89      0.88       275\n",
      "          N2       0.71      0.76      0.74       101\n",
      "          N3       0.89      0.77      0.82        70\n",
      "\n",
      "    accuracy                           0.88       737\n",
      "   macro avg       0.85      0.84      0.85       737\n",
      "weighted avg       0.88      0.88      0.88       737\n",
      "\n",
      "\n",
      "conditional memory, test size: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.98      0.96       282\n",
      "          N1       0.90      0.87      0.88       278\n",
      "          N2       0.73      0.77      0.75       103\n",
      "          N3       0.92      0.82      0.86        66\n",
      "\n",
      "    accuracy                           0.89       729\n",
      "   macro avg       0.87      0.86      0.86       729\n",
      "weighted avg       0.89      0.89      0.89       729\n",
      "\n",
      "\n",
      "conditional memory, test size: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.98      0.96       291\n",
      "          N1       0.91      0.87      0.89       277\n",
      "          N2       0.68      0.77      0.72        97\n",
      "          N3       0.98      0.76      0.85        66\n",
      "\n",
      "    accuracy                           0.89       731\n",
      "   macro avg       0.88      0.85      0.86       731\n",
      "weighted avg       0.90      0.89      0.89       731\n",
      "\n",
      "\n",
      "conditional memory, test size: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.93      0.98      0.96       286\n",
      "          N1       0.88      0.88      0.88       277\n",
      "          N2       0.73      0.72      0.72       106\n",
      "          N3       0.96      0.78      0.86        65\n",
      "\n",
      "    accuracy                           0.89       734\n",
      "   macro avg       0.88      0.84      0.86       734\n",
      "weighted avg       0.89      0.89      0.89       734\n",
      "\n",
      "\n",
      "conditional memory, test size: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.93      0.98      0.96       288\n",
      "          N1       0.89      0.87      0.88       271\n",
      "          N2       0.76      0.69      0.72       103\n",
      "          N3       0.84      0.84      0.84        64\n",
      "\n",
      "    accuracy                           0.89       726\n",
      "   macro avg       0.86      0.85      0.85       726\n",
      "weighted avg       0.88      0.89      0.88       726\n",
      "\n",
      "\n",
      "conditional memory, test size: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.93      0.98      0.95       286\n",
      "          N1       0.87      0.89      0.88       271\n",
      "          N2       0.74      0.68      0.71       100\n",
      "          N3       0.94      0.76      0.84        66\n",
      "\n",
      "    accuracy                           0.88       723\n",
      "   macro avg       0.87      0.83      0.85       723\n",
      "weighted avg       0.88      0.88      0.88       723\n",
      "\n",
      "\n",
      "conditional memory, test size: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.94      0.97      0.96       279\n",
      "          N1       0.89      0.90      0.90       273\n",
      "          N2       0.73      0.75      0.74        97\n",
      "          N3       0.96      0.75      0.84        67\n",
      "\n",
      "    accuracy                           0.89       716\n",
      "   macro avg       0.88      0.84      0.86       716\n",
      "weighted avg       0.90      0.89      0.89       716\n",
      "\n",
      "\n",
      "conditional memory, test size: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.93      0.98      0.96       277\n",
      "          N1       0.89      0.84      0.87       268\n",
      "          N2       0.65      0.73      0.69       100\n",
      "          N3       0.95      0.77      0.85        69\n",
      "\n",
      "    accuracy                           0.87       714\n",
      "   macro avg       0.85      0.83      0.84       714\n",
      "weighted avg       0.88      0.87      0.87       714\n",
      "\n",
      "\n",
      "conditional memory, test size: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.93      0.98      0.96       274\n",
      "          N1       0.87      0.91      0.89       266\n",
      "          N2       0.77      0.70      0.73       105\n",
      "          N3       0.94      0.71      0.81        65\n",
      "\n",
      "    accuracy                           0.89       710\n",
      "   macro avg       0.88      0.82      0.85       710\n",
      "weighted avg       0.88      0.89      0.88       710\n",
      "\n",
      "\n",
      "conditional memory, test size: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.95      0.98      0.96       266\n",
      "          N1       0.92      0.78      0.84       264\n",
      "          N2       0.54      0.83      0.65        96\n",
      "          N3       1.00      0.69      0.81        64\n",
      "\n",
      "    accuracy                           0.86       690\n",
      "   macro avg       0.85      0.82      0.82       690\n",
      "weighted avg       0.89      0.86      0.86       690\n",
      "\n",
      "\n",
      "conditional memory, test size: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N0       0.93      0.98      0.96       273\n",
      "          N1       0.92      0.83      0.87       266\n",
      "          N2       0.63      0.78      0.70        94\n",
      "          N3       0.89      0.75      0.81        64\n",
      "\n",
      "    accuracy                           0.88       697\n",
      "   macro avg       0.84      0.83      0.83       697\n",
      "weighted avg       0.88      0.88      0.88       697\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"zshot\")\n",
    "df = pd.read_csv(\"result/n03/brca_df_zs_n03.csv\")\n",
    "relax_n03_performance_report(df, \"zs_n_ans_str\")\n",
    "print()\n",
    "\n",
    "for size in range(10, 101, 5):\n",
    "    print(f\"conditional memory, test size: {size}\")\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/n03/saturation_test_result_{size}.csv\")\n",
    "    n03_performance_report(df, \"cmem_n_ans_str\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in range(10, 101, 10):\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/saturation_test_result_{size}.csv\")\n",
    "    n03_performance_report(df, \"cmem_n_ans_str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"cmem_n_ans_str\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe from csv file\n",
    "df = pd.read_csv(\"saturation_train_result_10.csv\")\n",
    "n03_performance_report(df, \"mem_n_ans_str\")\n",
    "df = pd.read_csv(\"saturation_train_result_20.csv\")\n",
    "n03_performance_report(df, \"mem_n_ans_str\")\n",
    "df = pd.read_csv(\"saturation_train_result_30.csv\")\n",
    "n03_performance_report(df, \"mem_n_ans_str\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfCorrection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
